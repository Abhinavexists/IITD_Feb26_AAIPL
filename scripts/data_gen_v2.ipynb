{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b8ef44-b5cd-421a-9aee-126eade4095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "client = AsyncOpenAI(base_url='http://0.0.0.0:8000/v1',api_key='nvm')\n",
    "model_name=\"gptoss120b/\"\n",
    "async def generate_async(prompt, idx):\n",
    "    try:\n",
    "        response = await client.responses.create(\n",
    "            model=model_name,  # or your preferred model\n",
    "            input=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=1.0,\n",
    "            top_p=1.0\n",
    "        )\n",
    "        \n",
    "        return idx, response.output[1].content[0].text\n",
    "    except Exception as e:\n",
    "        return idx, f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96def510-7c00-4576-a5ef-95b4bc8befcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt=\"\"\"You are an expert-level examiner creating extremely difficult MCQ questions about {topic}.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Generate ONLY ONE question per response (not multiple)\n",
    "2. Topic must be strictly: {topic}\n",
    "3. Make questions genuinely hard - trick 50%+ of experts\n",
    "4. keep in mind that it cannot include any numerical style seating arrangement e.g. how many permutations such arragement possible etc.\n",
    "5. Return ONLY valid JSON (no other text)\n",
    "\n",
    "FORMAT (must be exact):\n",
    "{{\n",
    "    \"topic\": \"<Topic of the Question>\",\n",
    "    \"question\": \"<full question text>\",\n",
    "    \"choices\": [\n",
    "        \"A) <choice A text>\",\n",
    "        \"B) <choice B text>\",\n",
    "        \"C) <choice C text>\",\n",
    "        \"D) <choice D text>\"\n",
    "    ],\n",
    "    \"answer\": \"<correct choice letter only>\",\n",
    "    \"explanation\": \"brief explanation within 100 words for why the answer is correct\"\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa734d9d-30cc-4508-a0d8-ded5c0d11798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [01:28<56:54,  3.45s/it]   "
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    topics = [\n",
    "    \"Logical Reasoning: Syllogisms\",\n",
    "    \"Puzzles: Seating Arrangements (Linear, Circular)\",\n",
    "    \"AI\",\n",
    "    \"NLP\"]\n",
    "\n",
    "    tasks = [generate_async(developer_prompt.format(topic=topics[1]), idx) for idx in range(1000)]\n",
    "\n",
    "    results = [None] * len(tasks)\n",
    "\n",
    "    for future in tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "        idx, output = await future\n",
    "        results[idx] = output\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = await main()\n",
    "\n",
    "final_output=[]\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"\\n[{i}] {r}\")\n",
    "    final_output.append(eval(r))\n",
    "    pd.DataFrame({'answer':final_output}).to_csv('Puzzles.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f754db5c-b264-4e44-b856-351f12f32b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace cache contents:\n",
      "  .locks\n",
      "    └─ models--microsoft--Phi-4-mini-instruct\n",
      "    └─ models--Unsloth--Llama-3.1-8B-Instruct\n",
      "    └─ models--mistralai--Mistral-7B-Instruct-v0.3\n",
      "    └─ models--unsloth--gpt-oss-20b-BF16\n",
      "    └─ models--google--gemma-3-12b-it\n",
      "  xet\n",
      "    └─ https___cas_serv-tGqkUaZf_CBPHQ6h\n",
      "    └─ logs\n",
      "  models--microsoft--Phi-4-mini-instruct\n",
      "    └─ snapshots\n",
      "    └─ refs\n",
      "    └─ blobs\n",
      "  models--Unsloth--Llama-3.1-8B-Instruct\n",
      "    └─ snapshots\n",
      "    └─ refs\n",
      "    └─ blobs\n",
      "  models--mistralai--Mistral-7B-Instruct-v0.3\n",
      "    └─ snapshots\n",
      "    └─ refs\n",
      "    └─ blobs\n",
      "  models--unsloth--gpt-oss-20b-BF16\n",
      "    └─ snapshots\n",
      "    └─ refs\n",
      "    └─ blobs\n",
      "  models--google--gemma-3-12b-it\n",
      "    └─ snapshots\n",
      "    └─ refs\n",
      "    └─ blobs\n",
      "  models--Qwen--Qwen2.5-14B-Instruct\n",
      "    └─ snapshots\n",
      "    └─ refs\n",
      "    └─ blobs\n",
      "  models--Qwen--Qwen3-4B\n",
      "    └─ snapshots\n",
      "    └─ refs\n",
      "    └─ blobs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "hf_cache = \"/root/.cache/huggingface\"\n",
    "print(\"HuggingFace cache contents:\")\n",
    "for item in os.listdir(hf_cache):\n",
    "    print(f\"  {item}\")\n",
    "    if os.path.isdir(os.path.join(hf_cache, item)):\n",
    "        subpath = os.path.join(hf_cache, item)\n",
    "        for subitem in os.listdir(subpath)[:5]:\n",
    "            print(f\"    └─ {subitem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce35e9fd-fcbb-4d4b-9656-f66a83273b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available snapshots: ['cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8']\n",
      "Full path: /root/.cache/huggingface/models--Qwen--Qwen2.5-14B-Instruct/snapshots/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8\n",
      "Contents: ['model-00008-of-00008.safetensors', 'model-00006-of-00008.safetensors', 'generation_config.json', 'model-00005-of-00008.safetensors', 'README.md', 'config.json', 'model.safetensors.index.json', 'vocab.json', 'model-00003-of-00008.safetensors', 'LICENSE']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "snap_path = \"/root/.cache/huggingface/models--Qwen--Qwen2.5-14B-Instruct/snapshots\"\n",
    "snapshots = os.listdir(snap_path)\n",
    "print(f\"Available snapshots: {snapshots}\")\n",
    "if snapshots:\n",
    "    snap_hash = snapshots[0]\n",
    "    full_path = os.path.join(snap_path, snap_hash)\n",
    "    print(f\"Full path: {full_path}\")\n",
    "    print(f\"Contents: {os.listdir(full_path)[:10]}\")  # First 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea3cc90-bdda-4053-8b66-67bd5d00e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../AAIPL/questions_training.json\n"
     ]
    }
   ],
   "source": [
    "!find .. -name \"questions_training.json\" -type f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3a553b-ff9f-462d-8700-820d2310dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking locations:\n",
      "  ../AAIPL/questions_training.json: ✓ FOUND\n",
      "  ../../questions_training.json: ✗ Not found\n",
      "  /workspace/AAIPL/questions_training.json: ✓ FOUND\n",
      "  questions_training.json: ✓ FOUND\n",
      "  ../questions_training.json: ✗ Not found\n",
      "\n",
      "Searching for questions_training.json:\n",
      "  Found: /workspace/AAIPL/questions_training.json\n",
      "\n",
      "Current directory: /workspace/AAIPL\n",
      "Files in current directory: ['README.ipynb', 'agen.yaml', 'qgen.yaml', 'utils', 'assets', '.dockerignore', '.ipynb_checkpoints', 'tutorial_config.yaml', 'tutorial.ipynb', 'agents', 'hf_models', 'tokenizers.py', 'Logical_Reasoning.csv', 'questions_training.json', 'gptoss120b', 'SETUP.md', 'data_gen_v2-family.py', 'EXECUTION_GUIDE.md', 'scripts', 'data_gen_v2.ipynb', 'requirements.txt', 'IMPLEMENTATION_PLAN.md', 'unsloth_compiled_cache', 'Mixed_Series.csv', 'data_gen_v2-series.py', 'Family_Tree.csv', 'Puzzles.csv', 'data_gen_v2.py', 'git.sh']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Check multiple possible locations\n",
    "locations_to_check = [\n",
    "    \"../AAIPL/questions_training.json\",\n",
    "    \"../../questions_training.json\",\n",
    "    \"/workspace/AAIPL/questions_training.json\",\n",
    "    \"questions_training.json\",\n",
    "    \"../questions_training.json\",\n",
    "]\n",
    "\n",
    "print(\"Checking locations:\")\n",
    "for loc in locations_to_check:\n",
    "    exists = os.path.exists(loc)\n",
    "    print(f\"  {loc}: {'✓ FOUND' if exists else '✗ Not found'}\")\n",
    "\n",
    "# Also search for the file\n",
    "print(\"\\nSearching for questions_training.json:\")\n",
    "result = glob.glob(\"/workspace/**/questions_training.json\", recursive=True)\n",
    "if result:\n",
    "    for path in result:\n",
    "        print(f\"  Found: {path}\")\n",
    "else:\n",
    "    print(\"  No results found\")\n",
    "\n",
    "# Print current working directory\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "print(f\"Files in current directory: {os.listdir('.')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b54d0a-582c-491d-b509-694d95d30317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First item:\n",
      "{\n",
      "  \"answer\": \"{'topic': 'Logical Reasoning: Syllogisms', 'question': 'Consider the following statements:\\\\n1. No architect is a surgeon.\\\\n2. Some engineer is an architect.\\\\n3. All surgeons are poets.\\\\n4. Some poets are not engineers.\\\\n5. No engineer is a detective.\\\\n6. Every detective is a botanist.\\\\n7. Some botanist is an architect.\\\\nWhich of the following conclusions necessarily follows from the above statements?', 'choices': ['A) Some poets are engineers.', 'B) Some architects are botanists.', 'C) No surgeons are detectives.', 'D) All detectives are not architects.'], 'answer': 'B', 'explanation': \\\"Statement 7 asserts that some botanists are architects, which directly translates to 'some architects are botanists'. None of the other options are guaranteed by the given premises.\\\"}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = json.load(open('questions_training.json'))\n",
    "print('First item:')\n",
    "print(json.dumps(data[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ddcd5f3-cd89-4fca-9070-e45573cf5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading questions_training.json...\n",
      "Loaded 3450 items\n",
      "\n",
      "Fixed 3450 questions (0 errors)\n",
      "Saved to questions_training_fixed.json\n",
      "\n",
      "First fixed item:\n",
      "{\n",
      "  \"topic\": \"Logical Reasoning: Syllogisms\",\n",
      "  \"question\": \"Consider the following statements:\\n1. No architect is a surgeon.\\n2. Some engineer is an architect.\\n3. All surgeons are poets.\\n4. Some poets are not engineers.\\n5. No engineer is a detective.\\n6. Every detective is a botanist.\\n7. Some botanist is an architect.\\nWhich of the following conclusions necessarily follows from the above statements?\",\n",
      "  \"choices\": [\n",
      "    \"A) Some poets are engineers.\",\n",
      "    \"B) Some architects are botanists.\",\n",
      "    \"C) No surgeons are detectives.\",\n",
      "    \"D) All detectives are not architects.\"\n",
      "  ],\n",
      "  \"answer\": \"B\",\n",
      "  \"explanation\": \"Statement 7 asserts that some botanists are architects, which directly translates to 'some architects are botanists'. None of the other options are guaranteed by the given premises.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "# Load the malformed data\n",
    "print(\"Loading questions_training.json...\")\n",
    "with open('questions_training.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(data)} items\")\n",
    "\n",
    "# Fix the structure\n",
    "fixed_data = []\n",
    "errors = 0\n",
    "\n",
    "for idx, item in enumerate(data):\n",
    "    try:\n",
    "        # Parse the stringified dict in the \"answer\" field\n",
    "        if isinstance(item.get('answer'), str):\n",
    "            # Try to parse as Python literal\n",
    "            question_data = ast.literal_eval(item['answer'])\n",
    "        else:\n",
    "            question_data = item['answer']\n",
    "\n",
    "        fixed_data.append(question_data)\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        if errors <= 3:  # Print first 3 errors\n",
    "            print(f\"Error at index {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the fixed data\n",
    "print(f\"\\nFixed {len(fixed_data)} questions ({errors} errors)\")\n",
    "with open('questions_training_fixed.json', 'w') as f:\n",
    "    json.dump(fixed_data, f)\n",
    "\n",
    "print(\"Saved to questions_training_fixed.json\")\n",
    "\n",
    "# Verify the first item\n",
    "if fixed_data:\n",
    "    print(\"\\nFirst fixed item:\")\n",
    "    print(json.dumps(fixed_data[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a25cc-c71a-411d-b8c4-7af24de6ed8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
